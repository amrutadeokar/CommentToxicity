# ğŸ›¡ï¸ Toxic Comment Detection System

A web-based application that detects toxic comments in real-time using Natural Language Processing (NLP) and deep learning. It prevents users from submitting toxic remarks by displaying a warning pop-up and blocking the message. When a user submits a non-toxic comment, a pop-up appears saying "Comment submitted successfully," and the comment is displayed under the respective post. If the comment is toxic, a pop-up appears saying "You cannot enter a toxic comment."

## ğŸ” Features

- ğŸ” User login interface  
- ğŸ’¬ Comment input section  
- âš ï¸ Real-time toxicity detection with a popup warning  
- âœ… Only non-toxic comments are submitted and displayed  
- ğŸ¤– LSTM model trained on labelled comment data  

## ğŸ› ï¸ Tech Stack

- Frontend: HTML, CSS, JavaScript  
- Backend: Python (Flask API)  
- Machine Learning: TensorFlow/Keras, LSTM, Word Embeddings  
- Dataset: [Toxic Comment Classification Challenge - Kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

## ğŸ–¼ï¸ Screenshots

https://github.com/amrutadeokar/CommentToxicity/blob/b38d0022f27643981ff3c2c6d976e70d6cb41a73/login.jpg



## ğŸ“¦ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/commenttoxicity.git
   cd commenttoxicity

