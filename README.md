# ğŸ›¡ï¸ Toxic Comment Detection System

A web-based application that detects toxic comments in real-time using Natural Language Processing (NLP) and deep learning. It prevents users from submitting toxic remarks by displaying a warning pop-up and blocking the message. When a user submits a non-toxic comment, a pop-up appears saying "Comment submitted successfully," and the comment is displayed under the respective post. If the comment is toxic, a pop-up appears saying "You cannot enter a toxic comment."

## ğŸ” Features

- ğŸ” User login interface  
- ğŸ’¬ Comment input section  
- âš ï¸ Real-time toxicity detection with a popup warning  
- âœ… Only non-toxic comments are submitted and displayed  
- ğŸ¤– LSTM model trained on labelled comment data  

## ğŸ› ï¸ Tech Stack

- Frontend: HTML, CSS, JavaScript  
- Backend: Python (Flask API)  
- Machine Learning: TensorFlow/Keras, LSTM, Word Embeddings  
- Dataset: [Toxic Comment Classification Challenge - Kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

## ğŸ–¼ï¸ Screenshots

https://github.com/amrutadeokar/CommentToxicity/blob/b38d0022f27643981ff3c2c6d976e70d6cb41a73/login.jpg
https://github.com/amrutadeokar/CommentToxicity/blob/7018d145ce044712ade7dddd16fcd8e5cedd6fc7/page2.jpg
https://github.com/amrutadeokar/CommentToxicity/blob/963f1e80453f29a17e53154bb13b628955eb8f9a/page3.jpg
https://github.com/amrutadeokar/CommentToxicity/blob/ac310235da045b42907b3446fbdc96d5fbb98f94/page4.jpg
https://github.com/amrutadeokar/CommentToxicity/blob/15e670fa44a23b79c4c7bb80c86f81e0c76e6540/page5.jpg
https://github.com/amrutadeokar/CommentToxicity/tree/e8fb6aff69dab7a7d55e23857948bedaafb1a278/Project%20Photos

## ğŸ“¦ Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/commenttoxicity.git
   cd commenttoxicity

