# 🛡️ Toxic Comment Detection System

A web-based application that detects toxic comments in real-time using Natural Language Processing (NLP) and deep learning. It prevents users from submitting toxic remarks by displaying a warning pop-up and blocking the message. When a user submits a non-toxic comment, a pop-up appears saying "Comment submitted successfully," and the comment is displayed under the respective post. If the comment is toxic, a pop-up appears saying "You cannot enter a toxic comment."

## 🔍 Features

- 🔐 User login interface  
- 💬 Comment input section  
- ⚠️ Real-time toxicity detection with a popup warning  
- ✅ Only non-toxic comments are submitted and displayed  
- 🤖 LSTM model trained on labelled comment data  

## 🛠️ Tech Stack

- Frontend: HTML, CSS, JavaScript  
- Backend: Python (Flask API)  
- Machine Learning: TensorFlow/Keras, LSTM, Word Embeddings  
- Dataset: [Toxic Comment Classification Challenge - Kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

## 🖼️ Screenshots

https://github.com/amrutadeokar/CommentToxicity/blob/b38d0022f27643981ff3c2c6d976e70d6cb41a73/login.jpg



## 📦 Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/commenttoxicity.git
   cd commenttoxicity

