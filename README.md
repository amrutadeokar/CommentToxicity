# 🛡️ Toxic Comment Detection System

A web-based application that detects toxic comments in real-time using Natural Language Processing (NLP) and deep learning. It prevents users from submitting toxic remarks by displaying a warning pop-up and blocking the message. When a user submits a non-toxic comment, a pop-up appears saying "Comment submitted successfully," and the comment is displayed under the respective post. If the comment is toxic, a pop-up appears saying "You cannot enter a toxic comment."

## 🔍 Features

- 🔐 User login interface  
- 💬 Comment input section  
- ⚠️ Real-time toxicity detection with a popup warning  
- ✅ Only non-toxic comments are submitted and displayed  
- 🤖 LSTM model trained on labelled comment data  

## 🛠️ Tech Stack

- Frontend: HTML, CSS, JavaScript  
- Backend: Python (Flask API)  
- Machine Learning: TensorFlow/Keras, LSTM, Word Embeddings  
- Dataset: [Toxic Comment Classification Challenge - Kaggle](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge)

## 🖼️ Screenshots

https://github.com/amrutadeokar/CommentToxicity/blob/b38d0022f27643981ff3c2c6d976e70d6cb41a73/login.jpg
https://github.com/amrutadeokar/CommentToxicity/blob/7018d145ce044712ade7dddd16fcd8e5cedd6fc7/page2.jpg
https://github.com/amrutadeokar/CommentToxicity/blob/963f1e80453f29a17e53154bb13b628955eb8f9a/page3.jpg
https://github.com/amrutadeokar/CommentToxicity/blob/ac310235da045b42907b3446fbdc96d5fbb98f94/page4.jpg
https://github.com/amrutadeokar/CommentToxicity/blob/15e670fa44a23b79c4c7bb80c86f81e0c76e6540/page5.jpg
https://github.com/amrutadeokar/CommentToxicity/tree/e8fb6aff69dab7a7d55e23857948bedaafb1a278/Project%20Photos

## 📦 Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/commenttoxicity.git
   cd commenttoxicity

